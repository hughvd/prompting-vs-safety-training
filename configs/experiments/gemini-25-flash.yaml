output:
  root: "data/experiments"
  experiment: "gemini-2.5-flash"
model:
  provider: "openai"
  base_url: "https://openrouter.ai/api/v1"
  name: "google/gemini-2.5-flash"
  api_key_env: "OPENROUTER_API_KEY"
  reasoning: true
generation:
  max_tokens: 1024
  temperature: 0.0
http:
  timeout: 60.0
run:
  dry_run: false
specs:
  directory: "specs"
  files:
    - id: "baseline"
      filename: "baseline.txt"
    - id: "S0_minimal"
      filename: "S0_minimal.txt"
    - id: "S1_principles"
      filename: "S1_principles.txt"
    - id: "S2_rules"
      filename: "S2_rules.txt"
    - id: "S3_minimal+principles"
      filename: "S3_minimal+principles.txt"
    - id: "S4_minimal+rules"
      filename: "S4_minimal+rules.txt"
    - id: "S5_principles+rules"
      filename: "S5_principles+rules.txt"
    - id: "S6_minimal+principles+rules"
      filename: "S6_minimal+principles+rules.txt"
evaluations:
  refusal:
    enabled: true
    config: "configs/evaluation/refusal.yaml"
    output_subdir: "refusal"
  capability:
    enabled: true
    config: "configs/evaluation/capability.yaml"
    output_subdir: "capability"
parallel:
  max_workers: 20            # number of concurrent workers inside a run
  max_prompts_per_worker: 50  # shard size for each dataset chunk
runs:
  count: 3                  # number of experiment replicas
  base_seed: 42             # per-run seed offset applied to dataset shuffles
